{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID Compliance Violation Detection\n",
    "\n",
    "1. **Distance Violation Detection**  \n",
    "This code implements `YOLOv3` and `Deep SORT` in order to perfrom real-time people tracking. Yolov3 is an algorithm that uses deep convolutional neural networks to perform object detection. We can feed the people detected into Deep SORT `(Simple Online and Realtime Tracking with a Deep Association Metric)` in order for a real-time object tracker to be created.\n",
    "\n",
    "2. **Face Mask Detection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python-dotenv\n",
    "#tenosrflow==2.0\n",
    "#opencv-python\n",
    "#matplotlib\n",
    "#seaborn\n",
    "#pillow\n",
    "#tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = os.getenv(\"BASE_PATH\")\n",
    "sys.path.append(BASE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import time, random\n",
    "import numpy as np\n",
    "from absl import app, flags, logging\n",
    "from absl.flags import FLAGS\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from yolov3_tf2.models import (\n",
    "    YoloV3, YoloV3Tiny\n",
    ")\n",
    "from yolov3_tf2.dataset import transform_images\n",
    "from yolov3_tf2.utils import draw_outputs, convert_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_sort import preprocessing\n",
    "from deep_sort import nn_matching\n",
    "from deep_sort.detection import Detection\n",
    "from deep_sort.tracker import Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import generate_detections as gdet\n",
    "from PIL import Image\n",
    "from scipy.spatial import distance\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Data Paths\n",
    "DATA_PATH = os.path.join(BASE_PATH, 'data/raw')\n",
    "OUT_DATA_PATH = os.path.join(BASE_PATH, 'data/processed')\n",
    "TEMP_DATA_PATH = os.path.join(BASE_PATH, \"data/temp\")\n",
    "test_filename = \"test\"\n",
    "test_video_file = os.path.join(DATA_PATH,'videos/{}.mp4'.format(test_filename))\n",
    "output_video_file = os.path.join(OUT_DATA_PATH,'videos/{}.avi'.format(test_filename))\n",
    "output_mp4video_file = os.path.join(OUT_DATA_PATH,'videos{}-c.mp4'.format(test_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(TEMP_DATA_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Model Paths\n",
    "CLASSES_PATH = os.path.join(BASE_PATH, 'data/common/cocolabels/coco.names')\n",
    "MODEL_PATH = os.path.join(BASE_PATH, 'models')\n",
    "YOLO_WEIGHTS_PATH = os.path.join(MODEL_PATH, 'yolov3/weights/yolov3.tf')\n",
    "deepsort_model_filename = os.path.join(MODEL_PATH,'deepsort/mars-small128.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup GPU system\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'tiny': False, #'yolov3 or yolov3-tiny'\n",
    "        'size': 416, #'resize images to'\n",
    "        'output_format': 'XVID', #'codec used in VideoWriter when saving video to file'\n",
    "        'num_classes': 80, #'number of classes in the model'\n",
    "        'max_cosine_distance': 0.5,\n",
    "        'nn_budget': None,\n",
    "        'nms_max_overlap':1.0\n",
    "       }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deepsort Model\n",
    "encoder = gdet.create_box_encoder(deepsort_model_filename, batch_size=1)\n",
    "metric = nn_matching.NearestNeighborDistanceMetric(\"cosine\", args['max_cosine_distance'], args['nn_budget'])\n",
    "tracker = Tracker(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLOv3\n",
    "if args['tiny']:\n",
    "    yolo = YoloV3Tiny(classes=args['num_classes'])\n",
    "else:\n",
    "    yolo = YoloV3(classes=args['num_classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo.load_weights(YOLO_WEIGHTS_PATH)\n",
    "logging.info('weights loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [c.strip() for c in open(CLASSES_PATH).readlines()]\n",
    "logging.info('classes loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised the video capture.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert os.path.exists(test_video_file)\n",
    "    vid = cv2.VideoCapture(test_video_file)\n",
    "    print(\"Initialised the video capture.\")\n",
    "except:\n",
    "    print(\"**ERR: Unable to load test video, using default URL\")\n",
    "    vid = cv2.VideoCapture('https://www.sample-videos.com/video/mp4/720/big_buck_bunny_720p_2mb.mp4')\n",
    "    print(\"Loaded default URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = None\n",
    "\n",
    "# by default VideoCapture returns float instead of int\n",
    "width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(vid.get(cv2.CAP_PROP_FPS))\n",
    "total_f = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "codec = cv2.VideoWriter_fourcc(*args['output_format'])\n",
    "out = cv2.VideoWriter(output_video_file, codec, fps, (width, height))\n",
    "frame_index = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_image(img):\n",
    "    img_in = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n",
    "    img_in = tf.expand_dims(img_in, 0)\n",
    "    img_in = transform_images(img_in, args['size'])\n",
    "    return img_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_predict(img_in):\n",
    "    boxes, scores, classes, nums = yolo.predict(img_in)\n",
    "    classes = classes[0]\n",
    "    names = []\n",
    "    for i in range(len(classes)):\n",
    "        names.append(class_names[int(classes[i])])\n",
    "    names = np.array(names)\n",
    "    converted_boxes = convert_boxes(img, boxes[0])\n",
    "    features = encoder(img, converted_boxes)    \n",
    "    detections = []\n",
    "    converted_boxes_lst = []\n",
    "    for bbox, score, class_name, feature in zip(converted_boxes, scores[0], names, features):\n",
    "        if class_name == 'person':\n",
    "            detections.append(Detection(bbox, score, class_name, feature))\n",
    "            converted_boxes_lst.append(converted_boxes)\n",
    "    return detections, converted_boxes_lst\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function which return the bottom center of every bbox\n",
    "def mid_point(img, bbox):\n",
    "    #get the coordinates\n",
    "    x1,y1,x2,y2 = bbox[0], bbox[1], bbox[2], bbox[3]\n",
    "    #compute bottom center of bbox\n",
    "    x_mid = int((x1+x2)/2)\n",
    "    y_mid = int(y2)\n",
    "    mid   = (x_mid,y_mid)\n",
    "\n",
    "    return mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 158 µs, sys: 0 ns, total: 158 µs\n",
      "Wall time: 57.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def compute_distance(traker_idx, mids, thresh):\n",
    "    p1 = []\n",
    "    p2 = []\n",
    "    dist = []\n",
    "    dvd = []\n",
    "    row = len(traker_idx)\n",
    "    dist = [] #np.zeros((row,row))\n",
    "    for i in range(row):\n",
    "        for j in range(i+1,row):\n",
    "            if i!=j:\n",
    "                p1.append(traker_idx[i])\n",
    "                p2.append(traker_idx[j])\n",
    "                dst = distance.euclidean(mids[i], mids[j])\n",
    "                dist.append(dst)\n",
    "                if dst <=thresh:\n",
    "                    dvd.append(True)\n",
    "                else:\n",
    "                    dvd.append(False)\n",
    "    return pd.DataFrame(zip(p1, p2, dist, dvd), columns =['pid1', 'pid2', 'distance', 'dvd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14 µs, sys: 4 µs, total: 18 µs\n",
      "Wall time: 34.8 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def find_closest(dist,num,thresh):\n",
    "    p1=[]\n",
    "    p2=[]\n",
    "    d=[]\n",
    "    for i in range(num):\n",
    "        for j in range(i,num):\n",
    "            if( (i!=j) & (dist[i][j]<=thresh)):\n",
    "                p1.append(i)\n",
    "                p2.append(j)\n",
    "                d.append(dist[i][j])\n",
    "    return p1,p2,d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 µs, sys: 4 µs, total: 16 µs\n",
      "Wall time: 28.8 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def check_dvd(tracker, threshold):\n",
    "    mids = []\n",
    "    tracker_idx = []\n",
    "    for track in tracker.tracks:\n",
    "        if not track.is_confirmed() or track.time_since_update > 1:\n",
    "            continue \n",
    "        \n",
    "        # get the coordinates\n",
    "        bbox = track.to_tlbr()\n",
    "        # Get the midpoints\n",
    "        mids.append(mid_point(img, bbox))\n",
    "        tracker_idx.append(track.track_id)\n",
    "    \n",
    "    # compute distance\n",
    "    #tracker_mid_df = pd.DataFrame(zip(traker_idx,mids), columns=['tracker_id', 'mid_pt'])\n",
    "    dist_df = compute_distance(tracker_idx, mids, threshold)\n",
    "    return dist_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23 µs, sys: 0 ns, total: 23 µs\n",
      "Wall time: 43.9 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def check_violation(df, track_id):\n",
    "    #print(\"First Check\",df[df['pid1'] == track_id & df['dvd'] == True].count())\n",
    "    #print(\"Second Check\",df[df['pid2'] == track_id & df['dvd'] == True].count())\n",
    "    #print(\"-->\",df[df['pid1'] == track_id & df['dvd'] == True])\n",
    "    \n",
    "    if (df[(df.pid1 == track_id) & (df.dvd == True)].shape[0] > 0):\n",
    "        return True\n",
    "    elif (df[(df.pid2 == track_id) & (df.dvd == True)].shape[0] > 0):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 443/443 [03:11<00:00,  1.81it/s]WARNING:absl:Empty Frame\n",
      "WARNING:absl:Empty Frame\n",
      "WARNING:absl:Empty Frame\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More than 3 empty frames found...\n",
      "CPU times: user 38min 31s, sys: 5min 3s, total: 43min 34s\n",
      "Wall time: 3min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "fps = 0.0\n",
    "count = 0 \n",
    "dvd_frame_idx = []\n",
    "dvd_person_idx = []\n",
    "dvd_mid_pt = []\n",
    "dvd_shortest_distance = []\n",
    "dvd_violation = []\n",
    "threshold = 100\n",
    "violation_count = 0\n",
    "t0 = time.time()\n",
    "pbar = tqdm(total=total_f)\n",
    "while True:\n",
    "    result, img = vid.read()\n",
    "    if img is None:\n",
    "        logging.warning(\"Empty Frame\")\n",
    "        time.sleep(0.1)\n",
    "        count+=1\n",
    "        if count < 3:\n",
    "            continue\n",
    "        else: \n",
    "            print(\"More than 3 empty frames found...\")\n",
    "            break\n",
    "    \n",
    "    # Else process the image found\n",
    "    img_in = transform_image(img)\n",
    "    \n",
    "    # Predict the objects using yolo\n",
    "    t1 = time.time()\n",
    "    \n",
    "    detections, converted_boxes = yolo_predict(img_in)\n",
    "    cmap = plt.get_cmap('tab20b')\n",
    "    colors = [cmap(i)[:3] for i in np.linspace(0, 1, 20)]\n",
    "    \n",
    "    # Call the tracker\n",
    "    tracker.predict()\n",
    "    tracker.update(detections)\n",
    "    mids = []\n",
    "    df = check_dvd(tracker, threshold)\n",
    "    for track in tracker.tracks:\n",
    "        if not track.is_confirmed() or track.time_since_update > 1:\n",
    "            continue \n",
    "        bbox = track.to_tlbr()\n",
    "        class_name = track.get_class()\n",
    "        color = colors[int(track.track_id) % len(colors)]\n",
    "        color = (0,255,0) #(0,0,255) #[i * 255 for i in color]\n",
    "        #print(df.shape)\n",
    "        if check_violation(df, track.track_id):\n",
    "            violation_count += 1\n",
    "            color = (0,0,255)\n",
    "        \n",
    "        cv2.rectangle(img, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), color, 2)\n",
    "        cv2.rectangle(img, (int(bbox[0]), int(bbox[1]-30)), \n",
    "                      (int(bbox[0])+(len(class_name)+len(str(track.track_id)))*17, \n",
    "                       int(bbox[1])), color, -1)\n",
    "        cv2.putText(img, class_name + \"-\" + str(track.track_id),\n",
    "                    (int(bbox[0]), int(bbox[1]-10)),0, 0.75, (255,255,255),2)\n",
    "    \n",
    "    out.write(img)\n",
    "    frame_index = frame_index + 1\n",
    "    pbar.update(1)\n",
    "    # press q to quit\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1762\n"
     ]
    }
   ],
   "source": [
    "print(violation_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_avi_to_mp4(avi_file_path, output_name):\n",
    "    os.popen(\"ffmpeg -i '{input}' -ac 2 -b:v 2000k -c:a aac -c:v libx264 -b:a 160k -vprofile high -bf 0 -strict experimental -f mp4 '{output}.mp4'\".format(input = avi_file_path, output = output_name))\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_avi_to_mp4(output_video_file, output_mp4video_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "distanceviolation",
   "language": "python",
   "name": "distanceviolation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
